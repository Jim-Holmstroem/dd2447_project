\documentclass[a4paper,11pt]{kth-mag}

\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{lmodern}
\usepackage[latin1]{inputenc}
\usepackage[swedish,english]{babel}
\usepackage{modifications}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{float}
\usepackage{helpers}

\newcommand{\Cpp}{\texttt{C++}}
\newcommand{\Gcc}{\texttt{gcc}}

\title{Implementation of ``The Train'' problem}

\subtitle{Statistical Methods in Applied Computer Science, DD2447\\ Final Project}
\foreigntitle{}
\author{
    Jim Holmstr\"{o}m \href{mailto:jimho@kth.se}{jimho@kth.se}
}
\date{\today}
\blurb{Teacher: Jens Lagergren} 
\trita{}
\begin{document}
    \frontmatter
    \pagestyle{empty}
    \removepagenumbers
    \maketitle
    \selectlanguage{english}
    \tableofcontents*
    \mainmatter
    \pagestyle{newchap}

    \chapter{The Problem}
        \section[problemformulation]{
            Problem formulation 
            \footnote{
                This formulation has some minor differences but it should still 
                be equivalent with the original one.
            }
        }
        G is undirected and all vertices has degree 3. At each vertex the edges
        are labeled 0,L, and R (an edge can have different labels at different
        vertices). So a vertex is a switch. Start positions and switch settings
        have uniform priors.

        A switch setting is a function $\sigma: V(G)\rightarrow\set{L,R}$, which
        has the natural interpretation. By a position we mean a pair $(v,e)$,
        where $v\in V(G)$ and $e\in E(G)$, with the interpretation that the
        train has passed $v$ and exited through $e$.
        
        (We leave out G and a instead have G implicit for all distributions and expressions.)

        Below we give a DP algorithm for $\cprob{s,O}{\sigma}$. We will
        estimate $\cprob{\sigma}{O}$ using MCMC and then $\cprob{s}{O}$
        using:
        \begin{equation}
            \label{eq:marginalization}
            \cprob{s}{O} 
            = \sum\limits_\sigma
                \cprob{s,\sigma}{O}
            = \sum\limits_\sigma
                \cprob{s}{\sigma,O}\cprob{\sigma}{O}
            = \sum\limits_\sigma
                \frac{
                    \cprob{s,O}{\sigma}\cprob{\sigma}{O}
                }{
                    \cprob{O}{\sigma}
                }
        \end{equation}

    The probability $p$ is $0.05$. Given $G,\sigma,s\in V(G)$ ($s$ is a stop
    position), $O\in\set{L,R,0}^T$ (observed switch signals), we can compute 
    $\cprob{s,O}{\sigma}$ using dynamic programming (DP) and in each step compute the probability
    of going from some position $s'$ to $s$ in $t$ steps and observing
    $O_{1:t}=\set{o_i}_{i=1}^t$ when the switch settings are $\sigma$. By doing this
    for all stop positions $s$ and then summing out the stop position, we
    obtain $\cprob{O}{\sigma}$ in time $\Ordo{N^2T}$, where $N=|V(G)|$.

    The states in our HMM are positions. The transition probabilities are
    always 1, i.e., given how we enter a vertex it is uniquely determined how
    we exit (since switches are fixed). Also, when passing a switch the correct
    direction of the label of the position is emitted with probability $1-p$
    and any different direction is emitted with probability $p/2$.

    Let $c(s,t)$ be computed as below (we want $c(s,t)$ to be the probability
    of going from some position $s'$ to $s=(v,e)$ in $t$ steps and observing
    $O_{1:t}$). Let $f=(u,v)$ and $g=(w,v)$ be the two edges that are incident
    with $v$ but different from $e$.

    \begin{equation}
        c(s,t) =
        \begin{cases}
            1/N, & t = 0 \\
            \left[c((u,f),t-1) + c((w,g),t-1)\right](1-p) & e = 0 \wedge o_t = 0 \\
            \left[c((u,f),t-1) + c((w,g),t-1)\right]p     & e = 0 \wedge o_t \neq 0 \\
            \left[c((u,f),t-1)               \right](1-p) & e = L \wedge o_t = L \wedge f = 0 \\
            \left[c((u,f),t-1)               \right]p     & e = L \wedge o_t \neq L \wedge f = 0 \\
            \left[c((u,f),t-1)               \right](1-p) & e = R \wedge o_t = R \wedge f = 0 \\
            \left[c((u,f),t-1)               \right]p     & e = R \wedge o_t \neq R \wedge f = 0 \\
        \end{cases}
    \end{equation}

    \chapter{Methodology}
        \section{Derivation}
        The underlying model for this problem is a HMM but to calculate $\cprob{s}{O}$ we need to reform it to the form of a HMM.
            \subsection{
                Marginalization 
                $\cprob{s}{O}
                =
                \sum\limits_\sigma \cprob{s,\sigma}{O}
            $}
                The first marginalization in \eqref{eq:marginalization} is 
                to get fixed $\sigma$ and thereby fixed transition 
                probabilities inside the $\sum\limits\sigma$ to make the 
                sub-problem tractable, the downside to this is that we get 
                $|\set{L,R}^N| = \Ordo{2^N}$ summations which is intractable. 
                This will later be approximated to overcome the intractability with a 
                Markov chain Monte Carlo (MCMC) method. 

            \subsection{
                Conditional probability 
                $\cprob{s,\sigma}{O}
                =
                \cprob{s}{\sigma,O}\cprob{\sigma}{O}
            $}
                From the definition of conditional probability we can factor out
                the $\left.\sigma \middle\vert O\right.$ distribution and by this setting it up for the MCMC later on.

            \subsection{
                Conditional probabilty 
                $\cprob{s}{\sigma,O}
                =
                \frac{
                    \cprob{s,O}{\sigma}
                }{
                    \cprob{O}{\sigma}}
            $}
                To get it $\cprob{s,O}{\sigma}$ to match the form of $\bar{\alpha_t}=\cprob{O_{1:T},\bar{s}}{model}$ with the fw and we can still calculate $\cprob{O}{\sigma}$ by marginalization on $s$.

        \section{HMM}
            
                $c$ vs $c_{\sigma}$
            
        \section{MCMC}
            *basic basic MCMC abstract theory
            *MCMC used for estimating $E{f(\sigma)}$ without the intractible process of going through all
            $\sigma$.
            *why is $E{f(\sigma)}$ = 
            sum $f(\sigma)\prob{\sigma}$ = $\sum_{sampled} f(\sigma)/N$
            *how it relates to our problem
                *$\bar{sigma}$ graph with the weights $Q(\bar{\sigma},\bar{\sigma}')$
                which have $2^N$ states and $(2^N)^2$ connections
                note about being to vast to search through (dim-devil)
            *different algorithms for implementing MCMC
            *compare the different ones shortly(what they assume or
            need for example)
            *explain why we chose it
            *how we chose Q what are the requirements for it
                *hamming distance measure and picking close ones (as we should
                accordingly)
                *why hamming? a more natural distance for switch settings than
                say euclidean or such.
                *step size ($\delta$) = 1 (tuning parameter)
            *abstractly relate to the graph (what is this type of graph
            called?)
        *describe the marginalization over states in $\cprob{sigma}{o}$ and why we need
        to do it


    \chapter{Results \& Discussion}
        *MCMC
            *convergence analysis
                *trace plot
                *autocorrelation?
                *test different distributions for step size.
                    *step-size effect
                        *to small step size => autocorrelation high (slow convergence)
                        *to big step size => low acceptence rate



\end{document}
