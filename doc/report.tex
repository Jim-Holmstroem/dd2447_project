\documentclass[a4paper,11pt]{kth-mag}

\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{lmodern}
\usepackage[latin1]{inputenc}
\usepackage[swedish,english]{babel}
\usepackage{modifications}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{enumitem}
\usepackage{float}
\usepackage{helpers}

\newcommand{\Cpp}{\texttt{C++}}
\newcommand{\Gcc}{\texttt{gcc}}

\title{Implementation of ``The Train'' problem}

\subtitle{Statistical Methods in Applied Computer Science, DD2447\\ Final Project}
\foreigntitle{}
\author{
    Jim Holmstr\"{o}m \href{mailto:jimho@kth.se}{jimho@kth.se}\\
    Johan Gardell \href{mailto:jgar@kth.se}{jgar@kth.se}
}
\date{\today}
\blurb{Teacher: Jens Lagergren} 
\trita{}
\begin{document}
    \frontmatter
    \pagestyle{empty}
    \removepagenumbers
    \maketitle
    \selectlanguage{english}
    \tableofcontents*
    \mainmatter
    \pagestyle{newchap}

    \chapter{The Problem}
        \section[problemformulation]{
            Problem formulation 
            \footnote{
                This formulation has some minor differences but it should still 
                be equivalent with the original one.
            }
        }
        G is undirected and all vertices has degree 3. At each vertex the edges
        are labeled 0,L, and R (an edge can have different labels at different
        vertices). So a vertex is a switch. Start positions and switch settings
        have uniform priors.

        A switch setting is a function $\sigma: V(G)\rightarrow\set{L,R}$, which
        has the natural interpretation. By a position we mean a pair $(v,e)$,
        where $v\in V(G)$ and $e\in E(G)$, with the interpretation that the
        train has passed $v$ and exited through $e$.

        Below we give a DP algorithm for $\cprob{s,O,G}{\sigma}$. We will
        estimate $\cprob{\sigma}{G,O}$ using MCMC and then $\cprob{s}{G,O}$
        using:
        \begin{equation}
            \cprob{s}{G,O} 
            = \sum\limits_\sigma
                \cprob{s,\sigma}{G,O}
            = \sum\limits_\sigma
                \cprob{s}{\sigma,G,O}\cprob{\sigma}{G,O}
            = \sum\limits_\sigma
                \frac{
                    \cprob{s,G,O}{\sigma}\cprob{\sigma}{G,O}
                }{
                    \cprob{G,O}{\sigma}
                }
        \end{equation}

    The probability $p$ is $0.05$. Given $G,\sigma,s\in V(G)$ ($s$ is a stop
    position), $O\in\set{L,R,0}^T$ (observed switch signals), we can compute 
    $\cprob{s,G,O}{\sigma}$ using DP and in each step compute the probability
    of going from some position $s'$ to $s$ in $t$ steps and observing
    $O_{1:t}=\set{o_i}_{i=1}^t$ when the switch settings are $\sigma$. By doing this
    for all stop positions $s$ and then summing out the stop position, we
    obtain $\cprob{O}{G,\sigma}$ in time $\Ordo{N^2T}$, where $N=|V(G)|$.

    The states in our HMM are positions. The transition probabilities are
    always 1, i.e., given how we enter a vertex it is uniquely determined how
    we exit (since switches are fixed). Also, when passing a switch the correct
    direction of the label of the position is emitted with probability $1-p$
    and any different direction is emitted with probability $p/2$.

    Let $c(s,t)$ be computed as below (we want $c(s,t)$ to be the probability
    of going from some position $s'$ to $s=(v,e)$ in $t$ steps and observing
    $O_{1:t}$). Let $f=(u,v)$ and $g=(w,v)$ be the two edges that are incident
    with $v$ but different from $e$.

    \begin{equation}
        c(s,t) =
        \begin{cases}
            1/N, & t = 0 \\
            \left[c((u,f),t-1) + c((w,g),t-1)\right](1-p) & e = 0 \wedge o_t = 0 \\
            \left[c((u,f),t-1) + c((w,g),t-1)\right]p     & e = 0 \wedge o_t \neq 0 \\
            \left[c((u,f),t-1)               \right](1-p) & e = L \wedge o_t = L \wedge f = 0 \\
            \left[c((u,f),t-1)               \right]p     & e = L \wedge o_t \neq L \wedge f = 0 \\
            \left[c((u,f),t-1)               \right](1-p) & e = R \wedge o_t = R \wedge f = 0 \\
            \left[c((u,f),t-1)               \right]p     & e = R \wedge o_t \neq R \wedge f = 0 \\
        \end{cases}
    \end{equation}

    \chapter{Implementation}

        *The ignoring of G. email Jens bout it

        *MCMC
            *basic basic MCMC abstract theory
            *MCMC used for estimating E[f(\sigma)] without going through all
            \sigma which is intractable. 
            *why is E[f(\sigma)] = sum f(\sigma)p(\sigma) = sum_sampled
            f(\sigma)
            *how it relates to our problem
                *\bar{sigma} graph with the weights Q(\bar{sigma},\bar{sigma}')
                which 2^N states and (2^N)^2 connections
                note about being to vast to search through (dim-devil)
            *different algorithms for implementing MCMC
            *compare the different ones shortly(what they assume or
            need for example)
            *explain why we chose it
            *how we chose Q what are the requirements for it
                *hamming distance measure and picking close ones (as we should
                accordingly)
                *why hamming? a more natural distance for switch settings than
                say euclidean or such.
            *abstractly relate to the graph (what is this type of graph
            called?)
        *describe the marginalization over states in p(sigma|o) and why we need
        to do it


    \chapter{Results \& Discussion}
        

\end{document}
